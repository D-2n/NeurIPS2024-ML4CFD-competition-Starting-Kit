{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3Gbk16NVlrFn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import airfrans as af\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu7e2RFYqmlV"
   },
   "source": [
    "In the notebook 3b we can see the architecture of a model. It is a MLP(Multiple Layer Perceptron) with encoder, hidden fully connected layers, and decoder.  \n",
    "The input has 7 nodes for 7 inputs:  \n",
    "- its position (two component in meter): 'x-position' and 'y-position'\n",
    "- the inlet velocity (two components in meter per second): 'x-inlet_velocity' and 'y-inlet_velocity'\n",
    "- the distance to the airfoil (one component in meter): distance_function\n",
    "- the normals (two components in meter, set to 0 if the point is not on the airfoil): 'x-normals', 'y-normals'  \n",
    "\n",
    "This means that each mesh point in each Simulation is a datapoint, so the input dimension is [7,1].  \n",
    "\n",
    "The output of the network should be the size 4 for:  \n",
    "- the velocity (two components in meter per second): 'x-velocity'and 'y-velocity'\n",
    "- the pressure divided by the specific mass (one component in meter squared per second squared): 'pressure'\n",
    "- the turbulent kinematic viscosity (one component in meter squared per second): 'turbulent_viscosity'\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "5ZKMgl6zRDak",
    "outputId": "c51de165-31a0-4776-8e0b-76cc6ce1388b"
   },
   "outputs": [],
   "source": [
    "# If you already have the data downloaded, just specify the directory name:\n",
    "directory_name = '../../TER/NOTEBOOKS/Dataset' # depends on where you have the data stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset (task: scarce, split: train): 100%|██████████| 200/200 [01:14<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_list, dataset_name = af.dataset.load(root = directory_name, task = 'scarce', train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_simulation_name = dataset_name[0]\n",
    "\n",
    "first_simulation = af.Simulation(root = directory_name, name = first_simulation_name, T = 298.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = first_simulation.position\n",
    "inlet_velocity = first_simulation.input_velocity\n",
    "distance = first_simulation.sdf\n",
    "normals = first_simulation.normals\n",
    "\n",
    "velocity = first_simulation.velocity\n",
    "pressure = first_simulation.pressure\n",
    "nu_t = first_simulation.nu_t #kinematic turbulent viscosity\n",
    "\n",
    "x_train = np.hstack((position, inlet_velocity, distance, normals))\n",
    "y_train = np.hstack((velocity, pressure, nu_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30):\n",
    "    simulation_name = dataset_name[i]\n",
    "    simulation = af.Simulation(root = directory_name, name = simulation_name, T = 298.15)\n",
    "    position = simulation.position\n",
    "    inlet_velocity = simulation.input_velocity\n",
    "    distance = simulation.sdf\n",
    "    normals = simulation.normals\n",
    "\n",
    "    velocity = simulation.velocity\n",
    "    pressure = simulation.pressure\n",
    "    nu_t = simulation.nu_t\n",
    "\n",
    "    x_train_add = np.hstack((position, inlet_velocity, distance, normals))\n",
    "    y_train_add = np.hstack((velocity, pressure, nu_t))\n",
    "    \n",
    "    x_train = np.vstack((x_train, x_train_add))\n",
    "    y_train = np.vstack((y_train, y_train_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "x_train_torch = torch.from_numpy(x_train)\n",
    "y_train_torch = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(7, 32),  \n",
    "            nn.Tanh(),       \n",
    "            nn.Linear(32, 32),  \n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 4) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh maps values between -1 and 1, good for normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 684685.7500\n",
      "Epoch [20/100], Loss: 684637.1875\n",
      "Epoch [30/100], Loss: 684586.1875\n",
      "Epoch [40/100], Loss: 684536.4375\n",
      "Epoch [50/100], Loss: 684489.3125\n",
      "Epoch [60/100], Loss: 684445.0625\n",
      "Epoch [70/100], Loss: 684403.8750\n",
      "Epoch [80/100], Loss: 684365.1250\n",
      "Epoch [90/100], Loss: 684327.9375\n",
      "Epoch [100/100], Loss: 684291.9375\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    y_pred = model(x_train_torch)  # Forward pass\n",
    "    loss = criterion(y_pred, y_train_torch)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
